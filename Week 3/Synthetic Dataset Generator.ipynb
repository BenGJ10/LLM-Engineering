{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4ecbdc-ae3d-41c4-88ed-715b4645d75b",
   "metadata": {},
   "source": [
    "# Synthetic Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc78c496-588a-4744-aa55-6709ff0a2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import ollama\n",
    "import requests\n",
    "import tempfile\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9106c69d-9e15-4b72-8796-4462d6736769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins with sk-proj-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "OPENAI = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if OPENAI:\n",
    "    print(f\"OpenAI API Key exists and begins with {OPENAI[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key is not working properly. Please recheck!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088e2c79-c809-4a9d-aa34-15fd21da4887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running...\n"
     ]
    }
   ],
   "source": [
    "OLLAMA = os.getenv('OLLAMA_MODEL')\n",
    "\n",
    "if OLLAMA:\n",
    "    print(\"Ollama is running...\")\n",
    "else:\n",
    "    print(\"Failed to establish connection to ollama. Please recheck!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b995b-daad-44a7-877c-fa1c7083bb1c",
   "metadata": {},
   "source": [
    "### Creating Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede80e9e-0777-409e-b333-bb2075c5da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a data generation expert specialized in creating high-quality, realistic synthetic datasets for business analysis and machine learning applications. \n",
    "Your role is to understand the business context and generate structured data that mimics real-world scenarios, reflecting typical patterns, anomalies, and variability seen in actual business operations. \n",
    "You will always generate data in the format requested (e.g., CSV, JSON, Parquet) and make educated assumptions to define relevant and meaningful columns if not specified.\n",
    "\n",
    "Key requirements:\n",
    "- Tailor the dataset to the specific business domain.\n",
    "- Include date/time, categorical, numerical, and text fields where applicable.\n",
    "- Use realistic ranges and distributions for prices, counts, and dates.\n",
    "- Inject minor noise or variability where appropriate to simulate real-world behavior.\n",
    "- Respect the requested output format strictly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ff885d-56b7-4fac-ac29-0fa6fb493477",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Please generate a synthetic dataset for the following business scenario. \n",
    "If specific columns are not provided, infer and create suitable ones based on your domain knowledge. \n",
    "Format the output as requested. Include about 50-75 rows of data unless specified otherwise.\n",
    "\n",
    "Example 1:\n",
    "Business: A luxury watch retail store\n",
    "Format: CSV\n",
    "Output:\n",
    "Item,Price,Quantity,Brand,Sale Date\n",
    "Superocean II,20000,3,Breitling,2025-04-08\n",
    "Daytona,32000,2,Rolex,2025-04-10\n",
    "Portugieser,15000,4,IWC,2025-04-11\n",
    "\n",
    "Example 2:\n",
    "Business: A ride-sharing platform operating in urban areas\n",
    "Format: CSV\n",
    "Output:\n",
    "Ride ID,Pickup Location,Dropoff Location,Fare (USD),Driver Rating,Trip Duration (min),Timestamp\n",
    "R12345,Midtown,Soho,18.50,4.9,16,2025-06-01 14:23:00\n",
    "R12346,Brooklyn,Downtown,22.10,4.7,23,2025-06-01 15:05:00\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2380b0-ffb1-4648-a6f2-dfb4cb67de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_format(data_format, num_records):\n",
    "    format_message = ''\n",
    "\n",
    "    if data_format.upper() == 'CSV':\n",
    "        format_message = 'Please provide the dataset in CSV format.'\n",
    "    elif data_format.upper() == 'JSON':\n",
    "        format_message = 'Please provide the dataset in JSON format.'\n",
    "    elif data_format.upper() == 'TABULAR':\n",
    "        format_message = 'Please provide the dataset in a tabular format (markdown style).'\n",
    "    else:\n",
    "        format_message = 'Please choose a valid dataset format: CSV, JSON, or Tabular.'\n",
    "\n",
    "    return f\"{format_message} Generate exactly {num_records} realistic records based on the business context.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e96f71f-f66a-48e6-a478-07ffc4a24a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_user_prompt(user_input, data_format, num_records):\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": user_input + dataset_format(data_format, num_records)}\n",
    "    ]\n",
    "\n",
    "  return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b960acd7-3df0-4ef1-9366-4ddfdd185fc0",
   "metadata": {},
   "source": [
    "### Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fedcd6d-93c7-4b37-a935-8bb70b0b7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(user_input, data_format, model_choice, num_records):\n",
    "    \n",
    "    messages = complete_user_prompt(user_input, data_format, num_records)\n",
    "\n",
    "    # Convert messages to plain prompt for non-chat models (like Ollama)\n",
    "    def convert_to_prompt(messages):\n",
    "        return \"\\n\".join(f\"{m['role'].capitalize()}: {m['content']}\" for m in messages)\n",
    "\n",
    "    if model_choice == \"OpenAI\":\n",
    "        try:\n",
    "            client = OpenAI()\n",
    "            response = client.chat.completions.create(\n",
    "                model = \"gpt-4o\",\n",
    "                messages = messages,\n",
    "                temperature = 0.7,\n",
    "                stream = True\n",
    "            )\n",
    "            full_response = \"\"\n",
    "            for chunk in response:\n",
    "                token = chunk.choices[0].delta.content or \"\"\n",
    "                full_response += token\n",
    "                yield full_response \n",
    "        except Exception as e:\n",
    "            yield f\"OpenAI API Error: {str(e)}\"\n",
    "\n",
    "    elif model_choice == \"Ollama\":\n",
    "        try:\n",
    "            from ollama import chat as ollama_chat\n",
    "            prompt = convert_to_prompt(messages)\n",
    "            stream = ollama_chat(\n",
    "                model = \"llama3\",\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                stream = True\n",
    "            )\n",
    "            full_response = \"\"\n",
    "            for chunk in stream:\n",
    "                token = chunk.get(\"message\", {}).get(\"content\", \"\")\n",
    "                full_response += token\n",
    "                yield full_response \n",
    "        except Exception as e:\n",
    "            yield f\"Ollama API Error: {str(e)}\"\n",
    "    \n",
    "    else:\n",
    "        yield f\"Unsupported model: {model_choice}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771fc39-bb1b-4e57-9d40-b755a9138462",
   "metadata": {},
   "source": [
    "### Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b644641-4c82-48db-9c59-af3d46d0551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://09e46aff9428d40a58.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://09e46aff9428d40a58.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks(title = \"Synthetic Data Generator\", theme = gr.themes.Soft()) as ui:\n",
    "    gr.Markdown(\"<h1 style='text-align: center;'>Synthetic Data Generator</h1>\")\n",
    "    gr.Markdown(\"Describe a business scenario to generate synthetic data using OpenAI or Ollama.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale = 1):\n",
    "            user_inputs = gr.Textbox(\n",
    "                label = \"Business Scenario & Data Requirements\",\n",
    "                placeholder = \"E.g., A startup analyzing food delivery order trends in urban cities...\",\n",
    "                lines = 15\n",
    "            )\n",
    "\n",
    "            model_choice = gr.Dropdown(\n",
    "                choices = [\"OpenAI\", \"Ollama\"],\n",
    "                label = \"Choose Model\",\n",
    "                value = \"OpenAI\"\n",
    "            )\n",
    "\n",
    "            target_format = gr.Radio(\n",
    "                choices = [\"CSV\", \"JSON\", \"Tabular\"],\n",
    "                label = \"Output Format\",\n",
    "                value = \"CSV\"\n",
    "            )\n",
    "\n",
    "            num_records = gr.Slider(\n",
    "                minimum = 10, maximum = 200, step = 10, value = 50,\n",
    "                label = \"Number of Records\"\n",
    "            )\n",
    "\n",
    "            with gr.Row():\n",
    "                generate_button = gr.Button(\"Generate\")\n",
    "                clear_button = gr.Button(\"Clear\")\n",
    "\n",
    "        with gr.Column(scale = 1):\n",
    "            output = gr.Textbox(\n",
    "                label = \"Generated Synthetic Data\",\n",
    "                lines = 30,\n",
    "                interactive = False,\n",
    "                show_copy_button = True\n",
    "            )\n",
    "\n",
    "    # Event bindings\n",
    "    generate_button.click(\n",
    "        fn = generate_dataset,\n",
    "        inputs = [user_inputs, target_format, model_choice, num_records],\n",
    "        outputs = output\n",
    "    )\n",
    "\n",
    "    clear_button.click(\n",
    "        fn = lambda: \"\",\n",
    "        inputs = [],\n",
    "        outputs = output\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ui.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e57608-f2bf-4d78-981d-ecff5a4e3a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
